@article{pitts, 
author = {Warren S. McCullogh and Walter H. Pitts},
title = {{A Logical Calculus of The Ideas In Nervous Activity}},
journal = {Bulletin of Mathematical Biophysics},
volume = {5}, 
pages = {115-133},
year = {1943}
}
@article{Jing2015,
abstract = {We demonstrate that, with the availability of distributed computation platforms such as Amazon Web Services and open-source tools, it is possible for a small engineering team to build, launch and maintain a cost-effective, large-scale visual search system. We also demonstrate, through a comprehensive set of live experiments at Pinterest, that content recommendation powered by visual search improves user engagement. By sharing our implementation details and learnings from launching a commercial visual search engine from scratch, we hope visual search becomes more widely incorporated into today's commercial applications.},
archivePrefix = {arXiv},
arxivId = {1505.07647},
author = {Jing, Yushi and Liu, David and Kislyuk, Dmitry and Zhai, Andrew and Xu, Jiajing and Donahue, Jeff and Tavel, Sarah},
doi = {10.1145/2783258.2788621},
eprint = {1505.07647},
file = {:Users/adam/university/bsc2/articles/visual{\_}search{\_}at{\_}pinterest.pdf:pdf},
isbn = {9781450336642},
journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
keywords = {Open source,Visual search,Visual shopping},
pages = {1889--1898},
title = {{Visual search at pinterest}},
volume = {2015-August},
year = {2015}
}
@article{Zhou2014,
abstract = {Traditionally, when generative models of data are developed via deep architectures, greedy layer-wise pre-training is employed. In a well-trained model, the lower layer of the architecture models the data distribution conditional upon the hidden variables, while the higher layers model the hidden distribution prior. But due to the greedy scheme of the layerwise training technique, the parameters of lower layers are fixed when training higher layers. This makes it extremely challenging for the model to learn the hidden distribution prior, which in turn leads to a suboptimal model for the data distribution. We therefore investigate joint training of deep autoencoders, where the architecture is viewed as one stack of two or more single-layer autoencoders. A single global reconstruction objective is jointly optimized, such that the objective for the single autoencoders at each layer acts as a local, layer-level regularizer. We empirically evaluate the performance of this joint training scheme and observe that it not only learns a better data model, but also learns better higher layer representations, which highlights its potential for unsupervised feature learning. In addition, we find that the usage of regularizations in the joint training scheme is crucial in achieving good performance. In the supervised setting, joint training also shows superior performance when training deeper models. The joint training framework can thus provide a platform for investigating more efficient usage of different types of regularizers, especially in light of the growing volumes of available unlabeled data.},
archivePrefix = {arXiv},
arxivId = {1405.1380},
author = {Zhou, Yingbo and Arpit, Devansh and Nwogu, Ifeoma and Govindaraju, Venu},
eprint = {1405.1380},
file = {:Users/adam/Downloads/1405.1380.pdf:pdf},
pages = {1--11},
title = {{Is Joint Training Better for Deep Auto-Encoders?}},
url = {http://arxiv.org/abs/1405.1380},
year = {2014}
}
@article{Krizhevsky2010,
abstract = {We show how to learn many layers of features on color images and we use these features to initialize deep autoencoders. We then use the autoencoders to map images to short binary codes. Using semantic hashing [6], 28-bit codes can be used to retrieve images that are similar to a query image in a time that is independent of the size of the database. This extremely fast retrieval makes it possible to search using multiple different transformations of the query image. 256-bit binary codes allow much more accurate matching and can be used to prune the set of images found using the 28-bit codes.},
author = {Krizhevsky, Alex and Hinton, Geoffrey E.},
file = {:Users/adam/university/bsc2/articles/esann-deep-final.pdf:pdf},
isbn = {9782874190445},
journal = {ESANN 2011 proceedings, 19th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
pages = {489--494},
title = {{Using very deep autoencoders for content-based image retrieval}},
year = {2010}
}
@article{Vincent2008,
abstract = {Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite. Copyright 2008 by the author(s)/owner(s).},
author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre Antoine},
doi = {10.1145/1390156.1390294},
file = {:Users/adam/Downloads/denoising{\_}autoencoders{\_}tr1316.pdf:pdf},
isbn = {9781605582054},
journal = {Proceedings of the 25th International Conference on Machine Learning},
pages = {1096--1103},
title = {{Extracting and composing robust features with denoising autoencoders}},
year = {2008}
}
@article{Bengio2009,
abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the stateof-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks. {\textcopyright} 2009 Y. Bengio.},
author = {Bengio, Yoshua},
doi = {10.1561/2200000006},
file = {:Users/adam/Downloads/TR1312.pdf:pdf},
issn = {19358237},
journal = {Foundations and Trends in Machine Learning},
number = {1},
pages = {1--27},
title = {{Learning deep architectures for AI}},
volume = {2},
year = {2009}
}
@article{HintonScience2006,
abstract = {Research during the past decade has greatly enriched our knowledge about the ways that curriculum design can impact learning in science. An important contribution comes from design-based research - an emerging methodology. Researchers have sought to synthesize refinement studies of curricular innovations. Frameworks to organize design knowledge are emerging. We demonstrate the potential use of such frameworks to guide the process of curricular design by describing two approaches for synthesizing design knowledge: the design principles and the design patterns approaches. Both approaches view science learning as a process of knowledge integration. These approaches can contribute to courses in curriculum design and help designers build on widely used materials to improve student learning. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
author = {G. E. Hinton* and R. R. Salakhutdinov},
doi = {10.1016/B978-0-08-044894-7.00081-6},
file = {:Users/adam/Downloads/science.pdf:pdf},
isbn = {9780080448947},
journal = {International Encyclopedia of Education},
keywords = {Assessment,Curriculum,Design patterns,Design principles,Design principles database,Knowledge integration,Scaffolding,Science education,Technology-enhanced learning in science (TELS),Web-based inquiry science environment (WISE)},
number = {July},
pages = {504--507},
title = {{Reducing the Dimensionality of Data with Neural Networks}},
volume = {313},
year = {2010}
}
@article{VincentBengio2008,
author = {Vincent, Larochelle, Bengio and Manzagol},
file = {:Users/adam/university/bsc2/articles/icml-2008-denoising-autoencoders.pdf:pdf},
doi = {10.1145/1390156.1390294},
journal = {ICML '08: Proceedings of the 25th international conference on Machine learning},
keywords = {undefined},
pages = {1096–1103},
title = {{Extracting and Composing Robust Features with Denoising Autoencoders}},
url = {https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf},
year = {2008}
}
@article{Salakhutdinov2009,
abstract = {We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs “semantic hashing”: Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set.},
author = {Salakhutdinov, Ruslan and Hinton, Geoffrey},
doi = {10.1016/j.ijar.2008.11.006},
file = {:Users/adam/university/bsc2/articles/semantic{\_}final.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {undefined},
number = {7},
pages = {969--978},
title = {{ScienceDirect - International Journal of Approximate Reasoning : Semantic hashing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0888613X08001813{\%}5Cnhttp://dx.doi.org/10.1016/j.ijar.2008.11.006},
volume = {50},
year = {2009}
}
@article{Xu2018,
abstract = {This paper is concerned with the open-circuit fault diagnosis of phase-controlled three-phase full-bridge rectifier by using a sparse autoencoder-based deep neural network (SAE-based DNN). Firstly, some preliminaries on SAE-based DNN are briefly introduced to automatically learn the representative fault features from the raw fault signals. Then, a novel strategy is developed to design the structure of the SAE-based DNN, by which the depth and hidden neurons of the SAE-based DNN could be regularly determined to extract the features of input signals. Furthermore, the fault model and system framework are presented to diagnose the open-circuit fault of the three-phase full-bridge rectifier. Finally, the effectiveness of the developed novel strategy is verified by the results of simulation experiments, and the superiority of the novel SAE-based DNN is evaluated by comparing with other frequently used approaches.},
author = {Xu, Lin and Cao, Maoyong and Song, Baoye and Zhang, Jiansheng and Liu, Yurong and Alsaadi, Fuad E.},
doi = {10.1016/j.neucom.2018.05.040},
file = {:Users/adam/university/bsc2/articles/icml-2008-denoising-autoencoders.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Deep neural network,Fault diagnosis,Feature extraction,Power rectifier,Sparse autoencoder},
pages = {1--10},
title = {{Open-circuit fault diagnosis of power rectifier using sparse autoencoder based deep neural network}},
volume = {311},
year = {2018}
}
@article{Krizhevsky2010,
abstract = {We show how to learn many layers of features on color images and we use these features to initialize deep autoencoders. We then use the autoencoders to map images to short binary codes. Using semantic hashing [6], 28-bit codes can be used to retrieve images that are similar to a query image in a time that is independent of the size of the database. This extremely fast retrieval makes it possible to search using multiple different transformations of the query image. 256-bit binary codes allow much more accurate matching and can be used to prune the set of images found using the 28-bit codes.},
author = {Krizhevsky, Alex and Hinton, Geoffrey E.},
file = {:Users/adam/university/bsc2/articles/esann-deep-final.pdf:pdf},
isbn = {9782874190445},
journal = {ESANN 2011 proceedings, 19th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
pages = {489--494},
title = {{Using very deep autoencoders for content-based image retrieval}},
year = {2010}
}
@article{Rajaraman2012,
abstract = {ContextRisk of obstetric complications increases linearly with rising maternal glycemia. Testing hemoglobin A1c (HbA1c) is an effective option to detect hyperglycemia, but its association with adverse pregnancy outcomes remains unclear. Emerging data sustain that an early HbA1c ≥5.9{\%} could act as a pregnancy risk marker.ObjectiveTo determine, in a multiethnic cohort, whether an early ≥5.9{\%} HbA1c could be useful to identify women without diabetes mellitus at increased pregnancy risk.Design and SettingA prospective study was conducted at Hospital del Mar, Barcelona, between April 2013 and September 2015.Patients and InterventionA total of 1631 pregnant women had an HbA1c measurement added to their first antenatal blood tests and were screened for gestational diabetes mellitus at 24 to 28 weeks' gestation.Outcome MeasuresPrimary outcome was macrosomia. Secondary outcomes were preeclampsia, preterm birth, and cesarean section rate.ResultsA total of 1228 pregnancies were included for outcome analysis. Women with HbA1c ≥5.9{\%} (n = 48) showed a higher rate of macrosomia (16.7{\%} vs 5.9{\%}, P = 0.008) and a tendency toward a higher rate of preeclampsia (9.32{\%} vs 3.9{\%}, P = 0.092). There were no statistically significant differences in other pregnancy outcomes. After adjusting for potential confounders, an HbA1c ≥5.9{\%} was independently associated with a 3-fold increased risk of macrosomia (95{\%} confidence interval, 1.127 to 8.603, P = 0.028) and preeclampsia (95{\%} confidence interval, 1.086 to 11.532, P = 0.036).ConclusionsIn a multiethnic population, an early HbA1c ≥5.9{\%} measurement identifies women at high risk for poorer pregnancy outcomes independently of gestational diabetes mellitus diagnosis later in pregnancy. Further studies are required to establish cutoff points adapted to each ethnic group and to assess whether early detection and treatment are of benefit.},
author = {Rajaraman, Anand and Ullman, Jeffrey David and Rajaraman, Anand and Ullman, Jeffrey David},
doi = {10.1017/cbo9781139058452.004},
file = {:Users/adam/university/bsc2/articles/ch3.pdf:pdf},
journal = {Mining of Massive Datasets},
pages = {53--107},
title = {{Finding Similar Items}},
year = {2012}
}
@article{Wang2014,
abstract = {Learning fine-grained image similarity is a challenging task. It needs to capture between-class and within-class image differences. This paper proposes a deep ranking model that employs deep learning techniques to learn similarity metric directly from images. It has higher learning capability than models based on hand-crafted features. A novel multiscale network structure has been developed to describe the images effectively. An efficient triplet sampling algorithm is also proposed to learn the model with distributed asynchronized stochastic gradient. Extensive experiments show that the proposed algorithm outperforms models based on hand-crafted visual features and deep classification models.},
archivePrefix = {arXiv},
arxivId = {1404.4661},
author = {Wang, Jiang and Song, Yang and Leung, Thomas and Rosenberg, Chuck and Wang, Jingbin and Philbin, James and Chen, Bo and Wu, Ying},
doi = {10.1109/CVPR.2014.180},
eprint = {1404.4661},
file = {:Users/adam/university/bsc2/articles/42945.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {1386--1393},
title = {{Learning fine-grained image similarity with deep ranking}},
year = {2014}
}
@article{Pulgar2018,
abstract = {High dimensionality tends to be a challenge for most machine learning tasks, including classification. There are different classification methodologies, of which instance-based learning is one. One of the best known members of this family is the k-nearest neighbors (kNNs) algorithm. Its strategy relies on searching a set of nearest instances. In high-dimensional spaces, the distances between examples lose significance. Therefore, kNN, in the same way as many other classifiers, tends to worsen its performance as the number of input variables grows. In this study, AEkNN, a new kNN-based algorithm with built-in dimensionality reduction, is presented. Aiming to obtain a new representation of the data, having a lower dimensionality but with more informational features, AEkNN internally uses autoencoders. From this new vector of features the computed distances should be more significant, thus providing a way to choose better neighbors. An experimental evaluation of the new proposal is conducted, analyzing several configurations and comparing them against the original kNN algorithm and classical dimensionality reduction methods. The obtained conclusions demonstrate that AEkNN offers better results in predictive and runtime performance.},
archivePrefix = {arXiv},
arxivId = {1802.08465},
author = {Pulgar, Francisco J. and Charte, Francisco and Rivera, Antonio J. and {Del Jesus}, Mar{\'{i}}a J.},
doi = {10.2991/ijcis.2018.125905686},
eprint = {1802.08465},
file = {:Users/adam/university/bsc2/articles/1802.08465.pdf:pdf},
issn = {18756883},
journal = {International Journal of Computational Intelligence Systems},
keywords = {Autoencoders,Deep learning,Dimensionality reduction,High dimensionality,KNN},
number = {1},
pages = {436--452},
title = {{AEkNN: An autoencoder kNN–based classifier with built-in dimensionality reduction}},
volume = {12},
year = {2018}
}
@article{Razavian2014,
abstract = {Recent results indicate that the generic descriptors extracted from the convolutional neural networks are very powerful. This paper adds to the mounting evidence that this is indeed the case. We report on a series of experiments conducted for different recognition tasks using the publicly available code and model of the OverFeat network which was trained to perform object classification on ILSVRC13. We use features extracted from the OverFeat network as a generic image representation to tackle the diverse range of recognition tasks of object image classification, scene recognition, fine grained recognition, attribute detection and image retrieval applied to a diverse set of datasets. We selected these tasks and datasets as they gradually move further away from the original task and data the OverFeat network was trained to solve. Astonishingly, we report consistent superior results compared to the highly tuned state-of-the-art systems in all the visual classification tasks on various datasets. For instance retrieval it consistently outperforms low memory footprint methods except for sculptures dataset. The results are achieved using a linear SVM classifier (or L2 distance in case of retrieval) applied to a feature representation of size 4096 extracted from a layer in the net. The representations are further modified using simple augmentation techniques e.g. jittering. The results strongly suggest that features obtained from deep learning with convolutional nets should be the primary candidate in most visual recognition tasks.},
archivePrefix = {arXiv},
arxivId = {1403.6382},
author = {Razavian, Ali Sharif and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
doi = {10.1109/CVPRW.2014.131},
eprint = {1403.6382},
file = {:Users/adam/university/bsc2/articles/1403.6382.pdf:pdf},
isbn = {9781479943098},
issn = {21607516},
journal = {IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops},
pages = {512--519},
title = {{CNN features off-the-shelf: An astounding baseline for recognition}},
year = {2014}
}
@article{Jansen1990,
abstract = {In this study the diagnostic accuracy of transrectal ultrasonography (TRUS) in identifying prostatic cancer has been investigated. Attention was paid to the localization of tumor, capsular penetration and involvement of seminal vesicles. TRUS was performed with a 5-mHz linear array longitudinal probe as well as with a 5-mHz rotating transverse scanner. 23 patients underwent radical prostatectomy. The histological results were compared with the sonographic patterns. Transverse TRUS and longitudinal TRUS were comparable with regard to all the investigated parameters. The sensitivity and specificity for the presence or absence of tumor were 70-75 and 54{\%}, respectively. When suspicion of capsular involvement was estimated in a prostatic lobe, a sensitivity of 89{\%} and a specificity of 21{\%} was found. When every separate ultrasonographically suspicious area of capsular breach was considered, there was a positive correlation of 63{\%}. Seminal vesicle infiltration is hard to identify and TRUS has a sensitivity of only 65-74{\%} with a specificity of 40-57{\%}.},
author = {Jansen, H. and Gallee, M. P. and Schroder, F. H.},
doi = {10.1159/000463903},
file = {:Users/adam/university/bsc2/articles/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf:pdf},
issn = {03022838},
journal = {European Urology},
keywords = {Cancer prostatic,Prostatectomy, radical,Transrectal ultrasound},
number = {3},
pages = {174--178},
title = {{Analysis of sonographic pattern in prostatic cancer: Comparison of longitudinal and transversal transrectal ultrasound with subsequent radical prostatectomy specimens}},
volume = {18},
year = {1990}
}
@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"
}
@article{Zhou2014,
abstract = {Traditionally, when generative models of data are developed via deep architectures, greedy layer-wise pre-training is employed. In a well-trained model, the lower layer of the architecture models the data distribution conditional upon the hidden variables, while the higher layers model the hidden distribution prior. But due to the greedy scheme of the layerwise training technique, the parameters of lower layers are fixed when training higher layers. This makes it extremely challenging for the model to learn the hidden distribution prior, which in turn leads to a suboptimal model for the data distribution. We therefore investigate joint training of deep autoencoders, where the architecture is viewed as one stack of two or more single-layer autoencoders. A single global reconstruction objective is jointly optimized, such that the objective for the single autoencoders at each layer acts as a local, layer-level regularizer. We empirically evaluate the performance of this joint training scheme and observe that it not only learns a better data model, but also learns better higher layer representations, which highlights its potential for unsupervised feature learning. In addition, we find that the usage of regularizations in the joint training scheme is crucial in achieving good performance. In the supervised setting, joint training also shows superior performance when training deeper models. The joint training framework can thus provide a platform for investigating more efficient usage of different types of regularizers, especially in light of the growing volumes of available unlabeled data.},
archivePrefix = {arXiv},
arxivId = {1405.1380},
author = {Zhou, Yingbo and Arpit, Devansh and Nwogu, Ifeoma and Govindaraju, Venu},
eprint = {1405.1380},
file = {:Users/adam/Downloads/1405.1380.pdf:pdf},
pages = {1--11},
title = {{Is Joint Training Better for Deep Auto-Encoders?}},
url = {http://arxiv.org/abs/1405.1380},
year = {2014}
}
@article{Yosinski2014,
abstract = {Many deep neural networks trained on natural images exhibit a curious phenomenon in common: on the first layer they learn features similar to Gabor filters and color blobs. Such first-layer features appear not to be specific to a particular dataset or task, but general in that they are applicable to many datasets and tasks. Features must eventually transition from general to specific by the last layer of the network, but this transition has not been studied extensively. In this paper we experimentally quantify the generality versus specificity of neurons in each layer of a deep convolutional neural network and report a few surprising results. Trans-ferability is negatively affected by two distinct issues: (1) the specialization of higher layer neurons to their original task at the expense of performance on the target task, which was expected, and (2) optimization difficulties related to splitting networks between co-adapted neurons, which was not expected. In an example network trained on ImageNet, we demonstrate that either of these two issues may dominate, depending on whether features are transferred from the bottom, middle, or top of the network. We also document that the transferability of features decreases as the distance between the base task and target task increases, but that transferring features even from distant tasks can be better than using random features. A final surprising result is that initializing a network with transferred features from almost any number of layers can produce a boost to generalization that lingers even after fine-tuning to the target dataset.},
archivePrefix = {arXiv},
arxivId = {1411.1792},
author = {Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
eprint = {1411.1792},
file = {:Users/adam/Downloads/5347-how-transferable-are-features-in-deep-neural-networks.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {January},
pages = {3320--3328},
title = {{How transferable are features in deep neural networks?}},
volume = {4},
year = {2014}
}
@article{Anzanello2011,
abstract = {Learning curves (LCs) are deemed effective tools for monitoring the performance of workers exposed to a new task. LCs provide a mathematical representation of the learning process that takes place as task repetition occurs. These curves were originally proposed by Wright in 1936 upon observing cost reduction due to repetitive procedures in production plants. Since then, LCs have been used to estimate the time required to complete production runs and the reduction in production costs as learning takes place, as well as to assign workers to tasks based on their performance profile. Further, effects of task interruption on workers' performance have also being modeled by modifications on the LCs. This wide variety of applications justifies the relevance of LCs in industrial applications. This paper presents the state of the art in the literature on learning and forgetting curves, describing the existing models, their limitations, and reported applications. Directions for future research on the subject are eventually proposed. Relevance to industry: The Learning Curve (LC) models described here can be used in a wide variety of industrial applications where workers endeavor new tasks. LC modeling enables better assignment of tasks to workers and more efficient production planning, and reduces production costs. {\textcopyright} 2011 Elsevier B.V.},
author = {Anzanello, Michel Jose and Fogliatto, Flavio Sanson},
doi = {10.1016/j.ergon.2011.05.001},
file = {:Users/adam/Downloads/ERGON2037.pdf:pdf},
issn = {01698141},
journal = {International Journal of Industrial Ergonomics},
keywords = {Forgetting curves,Learning curves,Production planning,Task allocation},
number = {5},
pages = {573--583},
title = {{Learning curve models and applications: Literature review and research directions}},
volume = {41},
year = {2011}
}
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@article{PanYang2010,
 author = {Pan, Sinno Jialin and Yang, Qiang},
 title = {A Survey on Transfer Learning},
 year = {2010},
 issue_date = {October 2010},
 publisher = {IEEE Educational Activities Department},
 address = {USA},
 volume = {22},
 number = {10},
 issn = {1041-4347},
 url = {https://doi.org/10.1109/TKDE.2009.191},
 doi = {10.1109/TKDE.2009.191},
 journal = {IEEE Trans. on Knowl. and Data Eng.},
 month = oct,
 pages = {1345–1359},
 numpages = {15},
 keywords = {machine learning, Transfer learning, Transfer learning, survey, machine learning, data mining., survey, data mining.}
}
@book{Pan2014,
abstract = {Supervised machine learning techniques have already been widely studied and applied to various real-world applications. However, most existing supervised algorithms work well only under a common assumption: the training and test data are represented by the same features and drawn from the same distribution. Furthermore, the performance of these algorithms heavily rely on collecting high quality and sufficient labeled training data to train a statistical or computational model to make predictions on the future data [57,86,132]. However, in many real-world scenarios, labeled training data are in short supply or can only be obtained with expensive cost. This problem has become a major bottleneck of making machine learning methods more applicable in practice.},
author = {Pan, Sinno Jialin},
doi = {10.1201/b17320},
file = {:Users/adam/Downloads/torrey.handbook09.pdf:pdf},
isbn = {9781466586758},
issn = {0912-8085},
journal = {Data Classification: Algorithms and Applications},
pages = {537--570},
title = {{Transfer learning}},
year = {2014}
}
@article{Zhuang2015,
abstract = {Transfer learning has attracted a lot of attention in the past decade. One crucial research issue in transfer learning is how to find a good representation for instances of different domains such that the divergence between domains can be reduced with the new representation. Recently, deep learning has been proposed to learn more robust or higherlevel features for transfer learning. However, to the best of our knowledge, most of the previous approaches neither minimize the difference between domains explicitly nor encode label information in learning the representation. In this paper, we propose a supervised representation learning method based on deep autoencoders for transfer learning. The proposed deep autoencoder consists of two encoding layers: an embedding layer and a label encoding layer. In the embedding layer, the distance in distributions of the embedded instances between the source and target domains is minimized in terms of KL-Divergence. In the label encoding layer, label information of the source domain is encoded using a softmax regression model. Extensive experiments conducted on three real-world image datasets demonstrate the effectiveness of our proposed method compared with several state-of-the-art baseline methods.},
author = {Zhuang, Fuzhen and Cheng, Xiaohu and Luo, Ping and Pan, Sinno Jialin and He, Qing},
file = {:Users/adam/Downloads/578.pdf:pdf},
isbn = {9781577357384},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Special Track on Machine Learning},
number = {Ijcai},
pages = {4119--4125},
title = {{Supervised representation learning: Transfer learning with deep autoencoders}},
volume = {2015-January},
year = {2015}
}
@misc{gkallia2017keras_places365,
title={Keras-VGG16-Places365},
author={Grigorios Kalliatakis},
year={2017},
publisher={GitHub},
howpublished={\url{https://github.com/GKalliatakis/Keras-VGG16-places365}},
}
@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}
@article{Chu2017,
abstract = {As one of the most popular unsupervised learning approaches, the autoencoder aims at transforming the inputs to the outputs with the least discrepancy. The conventional autoencoder and most of its variants only consider the one-to-one reconstruction, which ignores the intrinsic structure of the data and may lead to overfitting. In order to preserve the latent geometric information in the data, we propose the stacked similarity-aware autoencoders. To train each single autoencoder, we first obtain the pseudo class label of each sample by clustering the input features. Then the hidden codes of those samples sharing the same category label will be required to satisfy an additional similarity constraint. Specifically, the similarity constraint is implemented based on an extension of the recently proposed center loss. With this joint supervision of the autoencoder reconstruction error and the center loss, the learned feature representations not only can reconstruct the original data, but also preserve the geometric structure of the data. Furthermore, a stacked framework is introduced to boost the representation capacity. The experimental results on several benchmark datasets show the remarkable performance improvement of the proposed algorithm compared with other autoencoder based approaches.},
author = {Chu, Wenqing and Cai, Deng},
doi = {10.24963/ijcai.2017/216},
file = {:Users/adam/Downloads/0216.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning: Neural Networks,Machine Learning: Unsupervised Learning},
pages = {1561--1567},
title = {{Stacked similarity-aware autoencoders}},
year = {2017}
}
@article{wattenberg2016how,
  author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
  title = {How to Use t-SNE Effectively},
  journal = {Distill},
  year = {2016},
  url = {http://distill.pub/2016/misread-tsne},
  doi = {10.23915/distill.00002}
}
@incollection{NIPS2012_4824,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}
@article{ResNet2015,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{imagenetex,
author = {Ahmed, Khawaja and Irtaza, Aun and Iqbal, Muhammad},
year = {2017},
month = {04},
pages = {},
title = {Fusion of local and global features for effective image extraction},
journal = {Applied Intelligence},
doi = {10.1007/s10489-017-0916-1}
}
@article{Places365,
abstract = {The rise of multi-million-item dataset initiatives has enabled data-hungry machine learning algorithms to reach near-human semantic classification at tasks such as object and scene recognition. Here we describe the Places Database, a repository of 10 million scene photographs, labeled with scene semantic categories and attributes, comprising a quasi-exhaustive list of the types of environments encountered in the world. Using state of the art Convolutional Neural Networks, we provide impressive baseline performances at scene classification. With its high-coverage and high-diversity of exemplars, the Places Database offers an ecosystem to guide future progress on currently intractable visual recognition problems.},
archivePrefix = {arXiv},
arxivId = {1610.02055},
author = {Zhou, Bolei and Lapedriza, Agata and Torralba, Antonio and Oliva, Aude},
doi = {10.1167/17.10.296},
eprint = {1610.02055},
file = {:Users/adam/Downloads/places2{\_}arxiv.pdf:pdf},
issn = {1534-7362},
journal = {Journal of Vision},
number = {10},
pages = {296},
title = {{Places: An Image Database for Deep Scene Understanding}},
volume = {17},
year = {2017}
}
@article{Zeiler2012,
abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
archivePrefix = {arXiv},
arxivId = {1212.5701},
author = {Zeiler, Matthew D.},
eprint = {1212.5701},
file = {:Users/adam/Downloads/1212.5701.pdf:pdf},
title = {{ADADELTA: An Adaptive Learning Rate Method}},
url = {http://arxiv.org/abs/1212.5701},
year = {2012}
}
@article{Kingma2015,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy Lei},
eprint = {1412.6980},
file = {:Users/adam/Downloads/1412.6980.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
pages = {1--15},
title = {{Adam: A method for stochastic optimization}},
year = {2015}
}










