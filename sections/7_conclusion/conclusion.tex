Experimentation with transfer learning techniques on new domains has never been more accessible, given the ever increasing amount of available data and generous work of many researchers, releasing pretrained models for everyone to use in new and interesting ways.
\newline
\newline
In this report it has been established that the training of autoencoders for dimensionality reduction can be bootstrapped to a significant extent by extracting feature vectors from pretrained neural networks.
Choosing a suitable image augmentation scheme for pretrained networks has shown to be, overwhelmingly, the most important factor in producing good predictions and meaningful feature vectors.
Experimentation has shown that simple autoencoder architectures exhibit adeptness in learning domain adopted features.
Furthermore it has been established that feature vectors from pretrained networks with sufficient domain overlap perform surprisingly well out-of-the-box.
Training autoencoders on top of the feature vectors has evidently shown to yield more accurate predictions across all metrics by a small margin compared to aforementioned feature vectors.
\newline
\newline
Given the classification accuracy results obtained during experimentation, it seems reasonable to use autoencoders not only as feature extractors for similarity, but may prove to be excellent at producing well-separated clusters for classification.
\newline
\newline
In addressing the problem statement of this project, the results outlined in this report suggest that a good model for identifying related images to a query image can be trained with limited resources.
Such a model may serve as a solid first step in the direction of more user-centric services and tools for danish homeseekers.
The proposed modelling strategy should, however, generalize very well to other housing markets where data is available.



